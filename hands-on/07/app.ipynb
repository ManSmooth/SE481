{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App prediction server\n",
    "I use ipynb because I use remote kernel and would be a pain otherwise, LDA model is 1.9 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /opt/conda/envs/ir/lib/python3.10/site-packages (3.0.2)\n",
      "Requirement already satisfied: nltk in /opt/conda/envs/ir/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from flask) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from flask) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/conda/envs/ir/lib/python3.10/site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from flask) (1.7.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/ir/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/envs/ir/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/ir/lib/python3.10/site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install flask nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/amogus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/amogus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flask import Flask, request\n",
    "from scipy.sparse import hstack\n",
    "import pickle\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import joblib\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stopword_set, stemmer):\n",
    "    cleaned_text = text.translate(str.maketrans('', '', '!\"#$%&\\'()*+,.<=>?@[]^`{|}~' + u'\\xa0'))\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    cleaned_text = cleaned_text.translate(str.maketrans(string.whitespace, ' ' * len(string.whitespace), ''))\n",
    "    cleaned_text = ' '.join(['_variable_with_underscore' if '_' in t else t for t in cleaned_text.split()])\n",
    "    cleaned_text = ' '.join(['_variable_with_dash' if '-' in t else t for t in cleaned_text.split()])\n",
    "    cleaned_text = ' '.join(['_long_variable_name' if len(t) > 15 and t[0] != '#' else t for t in cleaned_text.split()])\n",
    "    cleaned_text = ' '.join(['_weburl' if t.startswith('http') and '/' in t else t for t in cleaned_text.split()])\n",
    "    cleaned_text = ' '.join(['_number' if re.sub('[\\\\/;:_-]', '', t).isdigit() else t for t in cleaned_text.split()])\n",
    "    cleaned_text = ' '.join(['_variable_    with_address' if re.match('.*0x[0-9a-f].*', t) else t for t in cleaned_text.split()])\n",
    "    cleaned_text = ' '.join(['_name_with_number' if re.match('.*[a-f]*:[0-9]*', t) else t for t in cleaned_text.split()])\n",
    "    cleaned_text = ' '.join(['_number_starts_with_one_character' if re.match('[a-f][0-9].*', t) else t for t in cleaned_text.split()])\n",
    "    cleaned_text = ' '.join(['_number_starts_with_three_characters' if re.match('[a-f]{3}[0-9].*', t) else t for t in cleaned_text.split()])\n",
    "    cleaned_text = ' '.join(['_version' if any(i.isdigit() for i in t) and t.startswith('v') else t for t in cleaned_text.split()])\n",
    "    cleaned_text = ' '.join(['_localpath' if ('\\\\' in t or '/' in t) and ':' not in t else t for t in cleaned_text.split()])\n",
    "    cleaned_text = ' '.join(['_image_size' if t.endswith('px') else t for t in cleaned_text.split()])\n",
    "    tokenized_text = word_tokenize(cleaned_text)\n",
    "\n",
    "    sw_removed_text = [word for word in tokenized_text if word not in stopword_set]\n",
    "    sw_removed_text = [word for word in sw_removed_text if len(word) > 2]\n",
    "    stemmed_text = ' '.join([stemmer.stem(w) for w in sw_removed_text])\n",
    "\n",
    "    return stemmed_text\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.tfidf_vectorizer = joblib.load('resources/tfidf_model.joblib')\n",
    "app.count_vectorizer = joblib.load('resources/count_model.joblib')\n",
    "app.lda = joblib.load('resources/lda_model.joblib')\n",
    "app.lgbm = joblib.load('resources/gbm_model_lda.joblib')\n",
    "app.stopword_set = set(stopwords.words())\n",
    "app.stemmer = PorterStemmer()\n",
    "\n",
    "@app.route('/predict', methods=['GET'])\n",
    "def predict_basic():\n",
    "    response_object = {'status': 'success'}\n",
    "    argList = request.args.to_dict(flat=False)\n",
    "    title = argList['title'][0]\n",
    "    body = argList['body'][0]\n",
    "    count = app.count_vectorizer.transform([preprocess(' '.join([title, body]), app.stopword_set, app.stemmer)])\n",
    "    tf_idf = app.tfidf_vectorizer.transform([preprocess(' '.join([title, body]), app.stopword_set, app.stemmer)])\n",
    "    lda = app.lda.transform(count)\n",
    "    predict = app.lgbm.predict_proba(hstack([tf_idf, lda]))\n",
    "    print(f\"{predict=}\")\n",
    "    response_object['predict_as'] = 'bug' if predict[0][1] > 0.5 else 'not bug'\n",
    "    response_object['bug_prob'] = predict[0][1]\n",
    "    return response_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "/opt/conda/envs/ir/lib/python3.10/site-packages/lightgbm/basic.py:1192: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning('Converting data to scipy sparse matrix.')\n",
      "127.0.0.1 - - [09/Mar/2024 10:04:54] \"GET /predict?title=cannot%20download%20file%20error%20404&body=can't%20download%20cant%20download%20error%20error HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.48806683080839175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48806683080839175\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.54300924831601e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.54300924831601e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15782072822091275, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15782072822091275\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9533501350980856, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9533501350980856\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "predict=array([[0.35926334, 0.64073666]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Mar/2024 10:04:58] \"GET /predict?title=hello%20students&body=my%20name%20is%20katpark HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.48806683080839175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48806683080839175\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.54300924831601e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.54300924831601e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15782072822091275, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15782072822091275\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9533501350980856, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9533501350980856\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "predict=array([[0.7255712, 0.2744288]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Mar/2024 10:05:11] \"GET /predict?title=cannot%20download%20file%20error%20404&body=can't%20download%20cant%20download%20error%20error%20bug HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.48806683080839175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48806683080839175\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.54300924831601e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.54300924831601e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15782072822091275, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15782072822091275\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9533501350980856, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9533501350980856\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "predict=array([[0.12632423, 0.87367577]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Mar/2024 10:05:16] \"GET /predict?title=cannot%20download%20file%20error%20404&body=can't%20download%20cant%20download%20error%20error%20bug%20bug%20bug%20bug HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.48806683080839175, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48806683080839175\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.54300924831601e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.54300924831601e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15782072822091275, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15782072822091275\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9533501350980856, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9533501350980856\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "predict=array([[0.1105239, 0.8894761]])\n"
     ]
    }
   ],
   "source": [
    "app.run(debug=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (IR) (Local)",
   "language": "python",
   "name": "ir"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
